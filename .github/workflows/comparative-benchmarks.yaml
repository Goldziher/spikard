name: Comparative Benchmarks

on:
  workflow_dispatch:
    inputs:
      suite:
        description: 'Workload suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - json-bodies
          - path-params
          - query-params
          - forms
          - multipart
          - streaming
      duration:
        description: 'Duration per workload (seconds)'
        required: false
        default: '10'
        type: string
      concurrency:
        description: 'Concurrent connections'
        required: false
        default: '100'
        type: string

concurrency:
  group: benchmarks-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  RUST_BACKTRACE: short
  CARGO_TERM_COLOR: always
  CARGO_INCREMENTAL: 0
  CARGO_PROFILE_RELEASE_DEBUG: 0

jobs:
  build-harness:
    name: Build Benchmark Tools
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v6

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: benchmark-harness

      - name: Build benchmark harness
        run: cargo build --manifest-path tools/benchmark-harness/Cargo.toml --release

      - name: Install oha load generator
        run: cargo install oha --locked

      - name: Package benchmark tools
        run: |
          mkdir -p artifacts/bin
          cp target/release/benchmark-harness artifacts/bin/benchmark-harness
          cp ~/.cargo/bin/oha artifacts/bin/oha
          chmod +x artifacts/bin/benchmark-harness artifacts/bin/oha

      - name: Upload benchmark tools
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-tools
          path: artifacts/bin/
          retention-days: 1
          if-no-files-found: error

  # Group 1: Spikard Rust + WASM + PHP (6 frameworks)
  spikard-rust-wasm-php:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - spikard-rust-validation
          - spikard-rust-raw
          - spikard-wasm-validation
          - spikard-wasm-raw
          - spikard-php-validation
          - spikard-php-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 2: Spikard Python + Ruby (4 frameworks)
  spikard-python-ruby:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - spikard-python-validation
          - spikard-python-raw
          - spikard-ruby-validation
          - spikard-ruby-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 3: Spikard Node.js + Bun (4 frameworks)
  spikard-nodejs-bun:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - spikard-node-validation
          - spikard-node-raw
          - spikard-bun-validation
          - spikard-bun-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 4: Python FastAPI + Robyn (5 frameworks)
  python-fastapi-robyn:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - fastapi-uvicorn-validation
          - fastapi-uvicorn-raw
          - fastapi-granian-validation
          - fastapi-granian-raw
          - robyn-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 5: Python Litestar (4 frameworks)
  python-litestar:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - litestar-uvicorn-validation
          - litestar-uvicorn-raw
          - litestar-granian-validation
          - litestar-granian-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 6: Node.js Fastify + Hono + Express (6 frameworks)
  nodejs-fastify-hono-express:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - fastify-validation
          - fastify-raw
          - hono-validation
          - hono-raw
          - express-validation
          - express-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 7: Node.js Elysia + MoroJS + Kito (5 frameworks)
  nodejs-elysia-morojs-kito:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - elysia-validation
          - morojs-validation
          - morojs-raw
          - kito-validation
          - kito-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  # Group 8: Ruby Hanami + Roda, PHP Phalcon + Trongate (7 frameworks)
  ruby-php-frameworks:
    name: "Benchmark: ${{ matrix.framework }}"
    needs: build-harness
    runs-on: ubuntu-latest
    timeout-minutes: 360
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        framework:
          - hanami-api-validation
          - hanami-api-raw
          - roda-validation
          - roda-raw
          - phalcon-validation
          - phalcon-raw
          - trongate-raw
    steps:
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup-benchmark-tools
      - uses: ./.github/actions/benchmark-framework
        with:
          framework: ${{ matrix.framework }}
          suite: ${{ inputs.suite || 'all' }}
          duration: ${{ inputs.duration || '10' }}
          concurrency: ${{ inputs.concurrency || '100' }}

  aggregate-results:
    name: Aggregate Benchmark Results
    runs-on: ubuntu-latest
    if: always()
    needs:
      - build-harness
      - spikard-rust-wasm-php
      - spikard-python-ruby
      - spikard-nodejs-bun
      - python-fastapi-robyn
      - python-litestar
      - nodejs-fastify-hono-express
      - nodejs-elysia-morojs-kito
      - ruby-php-frameworks
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v6

      - name: Download all benchmark artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: benchmark-results-*
          path: benchmark-results/artifacts
          merge-multiple: false

      - name: List downloaded artifacts
        run: |
          echo "Downloaded artifacts:"
          if [ -d "benchmark-results/artifacts" ]; then
            ls -la benchmark-results/artifacts/
            find benchmark-results/artifacts -name "profile.json" -exec echo "Found: {}" \;
          else
            echo "No artifacts downloaded"
          fi

      - name: Create aggregated results manually
        run: |
          mkdir -p benchmark-results

          # Create aggregated JSON structure
          cat > benchmark-results/aggregated.json <<'EOF'
          {
            "metadata": {
              "run_id": "${{ github.run_id }}",
              "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "workflow": "Comparative Benchmarks",
              "commit": "${{ github.sha }}",
              "branch": "${{ github.ref_name }}",
              "aggregated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "artifact_count": 0,
              "artifacts": []
            },
            "frameworks": [],
            "summary": {
              "total_frameworks": 0,
              "completed": 0,
              "failed": 0,
              "total_requests": 0,
              "total_duration_secs": 0.0
            }
          }
          EOF

          # Merge all profile.json files into frameworks array using jq if available
          if command -v jq >/dev/null 2>&1; then
            for profile in benchmark-results/artifacts/*/profile.json; do
              if [ -f "$profile" ]; then
                framework=$(dirname "$profile" | xargs basename | sed 's/benchmark-results-//')
                echo "Processing framework: $framework"

                # Add to frameworks array
                jq --arg fw "$framework" \
                   --slurpfile prof "$profile" \
                   '.frameworks += [{framework: $fw, profile: $prof[0], status: "completed"}] |
                    .summary.completed += 1 |
                    .summary.total_frameworks += 1' \
                   benchmark-results/aggregated.json > benchmark-results/aggregated.tmp
                mv benchmark-results/aggregated.tmp benchmark-results/aggregated.json
              fi
            done
          fi

      - name: Upload aggregated results
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-aggregated-results
          path: benchmark-results/aggregated.json
          retention-days: 90
