name: CI - Benchmarks

on:
  push:
    branches: [main]
    paths:
      - 'crates/spikard/**'
      - 'crates/spikard-http/**'
      - 'crates/spikard-py/**'
      - 'crates/spikard-node/**'
      - 'crates/spikard-rb/**'
      - 'crates/spikard-php/**'
      - 'crates/spikard-wasm/**'
      - 'packages/python/**'
      - 'packages/node/**'
      - 'packages/ruby/**'
      - 'packages/php/**'
      - 'tools/benchmark-harness/**'
      - 'testing_data/**'
      - '.github/workflows/ci-benchmarks.yaml'
  pull_request:
    branches: [main]
    paths:
      - 'crates/spikard/**'
      - 'crates/spikard-http/**'
      - 'crates/spikard-py/**'
      - 'crates/spikard-node/**'
      - 'crates/spikard-rb/**'
      - 'crates/spikard-php/**'
      - 'crates/spikard-wasm/**'
      - 'packages/python/**'
      - 'packages/node/**'
      - 'packages/ruby/**'
      - 'packages/php/**'
      - 'tools/benchmark-harness/**'
      - 'testing_data/**'
      - '.github/workflows/ci-benchmarks.yaml'

concurrency:
  group: ci-spikard-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  RUST_BACKTRACE: short
  CARGO_TERM_COLOR: always
  CARGO_INCREMENTAL: 0
  CARGO_PROFILE_DEV_DEBUG: 0
  BENCH_SUITE: ${{ github.event_name == 'pull_request' && 'json-bodies' || 'all' }}
  BENCH_DURATION: ${{ github.event_name == 'pull_request' && '10' || '30' }}
  BENCH_CONCURRENCY: ${{ github.event_name == 'pull_request' && '50' || '100' }}
  BENCH_WARMUP: ${{ github.event_name == 'pull_request' && '2' || '10' }}

defaults:
  run:
    shell: bash

permissions:
  contents: read

jobs:
  build-harness:
    name: Build Benchmark Harness
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v6

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: build-harness

      - name: Build benchmark-harness
        run: cargo build --manifest-path tools/benchmark-harness/Cargo.toml --release

      - name: Install oha load generator
        run: cargo install oha --locked

      - name: Install py-spy profiler
        run: cargo install py-spy --locked

      - name: Package benchmark tools
        run: |
          mkdir -p artifacts/bin
          cp target/release/benchmark-harness artifacts/bin/benchmark-harness
          cp ~/.cargo/bin/oha artifacts/bin/oha
          cp ~/.cargo/bin/py-spy artifacts/bin/py-spy
          chmod +x artifacts/bin/benchmark-harness artifacts/bin/oha artifacts/bin/py-spy

      - name: Upload benchmark tools artifact
        uses: actions/upload-artifact@v6
        with:
          name: bench-tools
          path: artifacts/bin/
          retention-days: 1
          if-no-files-found: error

  bench-spikard-rust:
    name: Benchmark spikard-rust
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: bench-rust

      - name: Build spikard-rust benchmark app
        working-directory: tools/benchmark-harness/apps/spikard-rust
        run: cargo build --release

      - name: Create results directory
        run: mkdir -p results/spikard-rust

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework spikard-rust \
            --app-dir tools/benchmark-harness/apps/spikard-rust \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler rust \
            --output results/spikard-rust/profile.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-spikard-rust
          path: results/spikard-rust/
          retention-days: 30

  bench-spikard-python:
    name: Benchmark spikard-python
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: bench-python-binding

      - name: Setup Python
        uses: ./.github/actions/setup-python-env
        with:
          python-version: "3.14"
          cache-prefix: bench-python

      - name: Build spikard-python binding
        uses: ./.github/actions/build-python-binding

      - name: Install benchmark app dependencies
        working-directory: tools/benchmark-harness/apps/spikard-python
        run: uv run pip install -e .

      - name: Create results directory
        run: mkdir -p results/spikard-python

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework spikard-python \
            --app-dir tools/benchmark-harness/apps/spikard-python \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler python \
            --output results/spikard-python/profile.json
        env:
          SPIKARD_METRICS_FILE: ${{ github.workspace }}/results/spikard-python/python-metrics.json
          SPIKARD_METRICS_DEBUG: "1"
          SPIKARD_PYINSTRUMENT_OUTPUT: ${{ github.workspace }}/results/spikard-python/pyinstrument.speedscope.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-spikard-python
          path: results/spikard-python/
          retention-days: 30

  bench-robyn-raw:
    name: Benchmark robyn-raw
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Python
        uses: ./.github/actions/setup-python-env
        with:
          python-version: "3.13"
          cache-prefix: bench-robyn-raw

      - name: Install benchmark app dependencies
        working-directory: tools/benchmark-harness/apps/robyn-raw
        run: uv run pip install -e .

      - name: Create results directory
        run: mkdir -p results/robyn-raw

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework robyn-raw \
            --app-dir tools/benchmark-harness/apps/robyn-raw \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler python \
            --output results/robyn-raw/profile.json
        env:
          SPIKARD_PYINSTRUMENT_OUTPUT: ${{ github.workspace }}/results/robyn-raw/pyinstrument.speedscope.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-robyn-raw
          path: results/robyn-raw/
          retention-days: 30

  bench-robyn-dto:
    name: Benchmark robyn-dto
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Python
        uses: ./.github/actions/setup-python-env
        with:
          python-version: "3.13"
          cache-prefix: bench-robyn-dto

      - name: Install benchmark app dependencies
        working-directory: tools/benchmark-harness/apps/robyn-dto
        run: uv run pip install -e .

      - name: Create results directory
        run: mkdir -p results/robyn-dto

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework robyn-dto \
            --app-dir tools/benchmark-harness/apps/robyn-dto \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler python \
            --output results/robyn-dto/profile.json
        env:
          SPIKARD_PYINSTRUMENT_OUTPUT: ${{ github.workspace }}/results/robyn-dto/pyinstrument.speedscope.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-robyn-dto
          path: results/robyn-dto/
          retention-days: 30

  bench-spikard-node:
    name: Benchmark spikard-node
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: bench-node-binding

      - name: Setup Node Workspace
        uses: ./.github/actions/setup-node-workspace
        with:
          node-version: "24"

      - name: Build spikard-node binding
        working-directory: packages/node
        run: pnpm build

      - name: Rebuild workspace after native build
        run: pnpm install --frozen-lockfile

      - name: Create results directory
        run: mkdir -p results/spikard-node

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework spikard-node \
            --app-dir tools/benchmark-harness/apps/spikard-node \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler node \
            --output results/spikard-node/profile.json
        env:
          SPIKARD_NODE_METRICS_FILE: ${{ github.workspace }}/results/spikard-node/node-metrics.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-spikard-node
          path: results/spikard-node/
          retention-days: 30

  bench-spikard-ruby:
    name: Benchmark spikard-ruby
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: bench-ruby-binding

      - name: Setup Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: "3.4"
          bundler: "4.0.0"
          bundler-cache: false

      - name: Build spikard-ruby binding
        uses: ./.github/actions/build-ruby-binding

      - name: Install benchmark app dependencies
        working-directory: tools/benchmark-harness/apps/spikard-ruby
        run: bundle install

      - name: Create results directory
        run: mkdir -p results/spikard-ruby

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework spikard-ruby \
            --app-dir tools/benchmark-harness/apps/spikard-ruby \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler ruby \
            --output results/spikard-ruby/profile.json
        env:
          SPIKARD_RUBY_METRICS_FILE: ${{ github.workspace }}/results/spikard-ruby/ruby-metrics.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-spikard-ruby
          path: results/spikard-ruby/
          retention-days: 30

  bench-spikard-php:
    name: Benchmark spikard-php
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: bench-php-binding

      - name: Setup LLVM/Clang
        uses: ./.github/actions/setup-llvm-clang

      - name: Setup OpenSSL
        uses: ./.github/actions/setup-openssl

      - name: Setup PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: "8.4"
          tools: composer
          coverage: none
          extensions: fileinfo, excimer

      - name: Verify PHP profiler extension
        run: php -m | grep -i excimer

      - name: Install PHP development headers
        run: bash scripts/ci/php/install-dev-headers-linux.sh

      - name: Build spikard-php extension
        run: cargo build --release -p spikard-php --features extension-module

      - name: Enable PHP extension
        run: |
          EXT_FILE=$(find target/release -name "libspikard_php.*" -o -name "spikard_php.*" | head -1)
          if [ -z "$EXT_FILE" ]; then
            echo "Failed to locate built PHP extension artifact under target/release" >&2
            exit 1
          fi
          EXT_DIR=$(php-config --extension-dir)
          sudo cp "$EXT_FILE" "$EXT_DIR/spikard_php.so"
          echo "extension=spikard_php.so" | sudo tee /etc/php/8.4/cli/conf.d/99-spikard.ini
          php -m | grep spikard

      - name: Install PHP package dependencies
        working-directory: packages/php
        run: composer install

      - name: Install benchmark app dependencies
        working-directory: tools/benchmark-harness/apps/spikard-php
        run: composer install

      - name: Create results directory
        run: mkdir -p results/spikard-php

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework spikard-php \
            --app-dir tools/benchmark-harness/apps/spikard-php \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --profiler php \
            --output results/spikard-php/profile.json
        env:
          SPIKARD_PHP_PROFILE_OUTPUT: ${{ github.workspace }}/results/spikard-php/php.speedscope.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-spikard-php
          path: results/spikard-php/
          retention-days: 30

  bench-spikard-wasm:
    name: Benchmark spikard-wasm
    runs-on: ubuntu-latest
    needs: build-harness
    timeout-minutes: 75
    steps:
      - uses: actions/checkout@v6

      - name: Download benchmark tools
        uses: actions/download-artifact@v7
        with:
          name: bench-tools
          path: ~/.cargo/bin

      - name: Make benchmark tools executable
        run: chmod +x ~/.cargo/bin/benchmark-harness ~/.cargo/bin/oha ~/.cargo/bin/py-spy

      - name: Setup Rust
        uses: ./.github/actions/setup-rust
        with:
          cache-key-prefix: bench-wasm-binding

      - name: Setup Node Workspace
        uses: ./.github/actions/setup-node-workspace
        with:
          node-version: "24"

      - name: Setup Deno
        uses: denoland/setup-deno@v2
        with:
          deno-version: latest

      - name: Build spikard-wasm binding
        run: |
          cd "$GITHUB_WORKSPACE/crates/spikard-wasm"
          pnpm run build:node
          pnpm run build:web
          cd "$GITHUB_WORKSPACE/packages/wasm"
          pnpm run build

      - name: Rebuild workspace after WASM build
        run: pnpm install --frozen-lockfile

      - name: Create results directory
        run: mkdir -p results/spikard-wasm

      - name: Run benchmarks
        run: |
          benchmark-harness profile \
            --framework spikard-wasm \
            --app-dir tools/benchmark-harness/apps/spikard-wasm \
            --suite "$BENCH_SUITE" \
            --duration "$BENCH_DURATION" \
            --concurrency "$BENCH_CONCURRENCY" \
            --warmup "$BENCH_WARMUP" \
            --output results/spikard-wasm/profile.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-results-spikard-wasm
          path: results/spikard-wasm/
          retention-days: 30
