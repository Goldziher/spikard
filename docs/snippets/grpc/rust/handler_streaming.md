# Rust gRPC Streaming Handlers

Complete Rust implementation examples for client streaming and bidirectional streaming gRPC handlers in Spikard.

## Client Streaming Handler

Client streaming RPC allows a client to send multiple messages and then the server responds with a single message.

### Handler Signature

```rust
use bytes::Bytes;
use spikard_http::grpc::{GrpcClientStreamRequest, GrpcResponse};
use tonic::metadata::MetadataMap;

pub struct GrpcClientStreamRequest {
    /// Service name (e.g., "myservice.MyService")
    pub service_name: String,
    /// Method name (e.g., "BatchCreate")
    pub method_name: String,
    /// Request metadata from client
    pub metadata: MetadataMap,
    /// All client messages collected as Vec
    pub messages: Vec<Bytes>,
}

async fn handle_client_stream(
    request: GrpcClientStreamRequest,
) -> Result<GrpcResponse, tonic::Status> {
    // Process all messages and return single response
}
```

### Example: Batch Message Processing

```rust
use bytes::Bytes;
use prost::Message;
use spikard_http::grpc::{GrpcClientStreamRequest, GrpcResponse};
use tonic::{Status, metadata::MetadataMap};
use std::sync::Arc;

// Generated protobuf types
mod messageservice {
    include!("messageservice.rs");  // Generated by prost
}

/// Handle client streaming: receive multiple messages, send single response.
///
/// Pattern: Collect all input messages, process together, return aggregated response.
pub async fn handle_batch_create(
    request: GrpcClientStreamRequest,
    repository: Arc<dyn ItemRepository + Send + Sync>,
) -> Result<GrpcResponse, Status> {
    let messages = request.messages;
    let metadata = request.metadata;

    // Validate authorization
    let auth_token = metadata
        .get("authorization")
        .and_then(|v| v.to_str().ok());

    if auth_token.is_none() {
        return Err(Status::unauthenticated("Authentication required"));
    }

    // Step 1: Deserialize all input messages
    let mut items = Vec::with_capacity(messages.len());
    for (index, msg) in messages.iter().enumerate() {
        let item = messageservice::Item::decode(msg.clone())
            .map_err(|e| {
                Status::invalid_argument(format!("Failed to decode message {}: {}", index, e))
            })?;
        items.push(item);
    }

    // Validate all items before processing
    for item in &items {
        if item.name.is_empty() || item.value == 0 {
            return Err(Status::invalid_argument(
                "Each item must have name and value"
            ));
        }
    }

    // Step 2: Process all items atomically
    let mut success_count = 0u32;
    let mut total_value = 0i32;

    // Simulate database transaction
    repository.with_transaction(|tx| async move {
        for item in items {
            tx.items().create(&item.name, item.value).await
                .map_err(|e| Status::internal(format!("Transaction failed: {}", e)))?;
            success_count += 1;
            total_value += item.value;
        }
        Ok::<_, Status>(())
    }).await?;

    // Step 3: Build aggregate response
    let batch_id = uuid::Uuid::new_v4().to_string();
    let timestamp = chrono::Utc::now().to_rfc3339();

    let response = messageservice::BatchCreateResponse {
        success_count,
        total_value,
        batch_id: batch_id.clone(),
        timestamp,
    };

    // Step 4: Serialize and return
    let mut buf = Vec::new();
    response.encode(&mut buf)
        .map_err(|e| Status::internal(format!("Encoding error: {}", e)))?;

    let mut response_metadata = MetadataMap::new();
    response_metadata.insert(
        "x-batch-id",
        batch_id.parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );
    response_metadata.insert(
        "x-count",
        success_count.to_string().parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );

    Ok(GrpcResponse {
        payload: Bytes::from(buf),
        metadata: response_metadata,
    })
}

// Mock trait for demonstration
#[async_trait::async_trait]
pub trait ItemRepository {
    async fn with_transaction<F, Fut, T>(&self, f: F) -> Result<T, Box<dyn std::error::Error>>
    where
        F: FnOnce(&dyn Transaction) -> Fut + Send,
        Fut: std::future::Future<Output = Result<T, Status>> + Send;
}

#[async_trait::async_trait]
pub trait Transaction: Send + Sync {
    fn items(&self) -> &dyn ItemStore;
}

#[async_trait::async_trait]
pub trait ItemStore: Send + Sync {
    async fn create(&self, name: &str, value: i32) -> Result<(), Box<dyn std::error::Error>>;
}
```

## Bidirectional Streaming Handler

Bidirectional streaming RPC allows the client to send multiple messages and the server to send multiple messages back.

### Handler Signature

```rust
use bytes::Bytes;
use spikard_http::grpc::{GrpcBidiStreamRequest, GrpcBidiStreamResponse};
use tonic::metadata::MetadataMap;

pub struct GrpcBidiStreamRequest {
    /// Service name (e.g., "myservice.MyService")
    pub service_name: String,
    /// Method name (e.g., "TransformStream")
    pub method_name: String,
    /// Request metadata from client
    pub metadata: MetadataMap,
    /// All input messages collected as Vec
    pub messages: Vec<Bytes>,
}

pub struct GrpcBidiStreamResponse {
    /// Array of response messages
    pub messages: Vec<Bytes>,
    /// Response metadata
    pub metadata: MetadataMap,
}

async fn handle_bidi_stream(
    request: GrpcBidiStreamRequest,
) -> Result<GrpcBidiStreamResponse, tonic::Status> {
    // Process input messages and generate output messages
}
```

### Example: Message Transformation Pipeline

```rust
use bytes::Bytes;
use prost::Message;
use spikard_http::grpc::{GrpcBidiStreamRequest, GrpcBidiStreamResponse};
use tonic::{Status, metadata::MetadataMap};

// Generated protobuf types
mod transformservice {
    include!("transformservice.rs");  // Generated by prost
}

/// Handle bidirectional streaming: receive multiple messages, send multiple messages.
///
/// Pattern: Collect all input messages, process, generate output messages, return Vec.
pub async fn handle_transform_stream(
    request: GrpcBidiStreamRequest,
) -> Result<GrpcBidiStreamResponse, Status> {
    let messages = request.messages;
    let _metadata = request.metadata;

    // Step 1: Deserialize all input messages
    let mut input_documents = Vec::with_capacity(messages.len());
    for (index, msg) in messages.iter().enumerate() {
        let document = transformservice::Document::decode(msg.clone())
            .map_err(|e| {
                Status::invalid_argument(format!("Failed to decode message {}: {}", index, e))
            })?;
        input_documents.push((index, document));
    }

    // Step 2: Process each document and generate response
    let mut output_messages = Vec::with_capacity(input_documents.len());

    for (index, document) in input_documents {
        match transform_document(&document).await {
            Ok(transformed) => {
                // Build response message
                let mut metadata_map = std::collections::HashMap::new();
                metadata_map.insert(
                    "original_size".to_string(),
                    document.content.len().to_string(),
                );
                metadata_map.insert(
                    "transformed_size".to_string(),
                    transformed.content.len().to_string(),
                );

                let result = transformservice::TransformResult {
                    original_id: document.id,
                    transformed_content: transformed.content,
                    transformed_at: chrono::Utc::now().to_rfc3339(),
                    status: if transformed.success { "SUCCESS" } else { "PARTIAL" }.to_string(),
                    metadata: metadata_map,
                    error_message: String::new(),
                };

                // Serialize response message
                let mut buf = Vec::new();
                result.encode(&mut buf)
                    .map_err(|e| Status::internal(format!("Encoding error: {}", e)))?;
                output_messages.push(Bytes::from(buf));
            }
            Err(err) => {
                // Create error response for this document
                let error_result = transformservice::TransformResult {
                    original_id: document.id,
                    transformed_content: String::new(),
                    transformed_at: String::new(),
                    status: "ERROR".to_string(),
                    metadata: std::collections::HashMap::new(),
                    error_message: err.to_string(),
                };

                let mut buf = Vec::new();
                error_result.encode(&mut buf)
                    .map_err(|e| Status::internal(format!("Encoding error: {}", e)))?;
                output_messages.push(Bytes::from(buf));
            }
        }
    }

    // Step 3: Return all response messages
    let mut response_metadata = MetadataMap::new();
    response_metadata.insert(
        "x-processed-count",
        output_messages.len().to_string().parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );
    response_metadata.insert(
        "x-timestamp",
        chrono::Utc::now().to_rfc3339().parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );

    Ok(GrpcBidiStreamResponse {
        messages: output_messages,
        metadata: response_metadata,
    })
}

struct TransformResult {
    content: String,
    success: bool,
}

async fn transform_document(doc: &transformservice::Document) -> Result<TransformResult, Box<dyn std::error::Error>> {
    // Simulate async transformation work
    Ok(TransformResult {
        content: doc.content.to_uppercase(),
        success: true,
    })
}
```

## Advanced Example: Filtering and Aggregation

### Bidirectional Stream with Filtering

```rust
use bytes::Bytes;
use prost::Message;
use spikard_http::grpc::{GrpcBidiStreamRequest, GrpcBidiStreamResponse};
use tonic::{Status, metadata::MetadataMap};

// Generated protobuf types
mod recordservice {
    include!("recordservice.rs");  // Generated by prost
}

/// Filter records and apply transformations in bidirectional stream.
///
/// Pattern: Filter input based on metadata criteria, transform, return filtered output.
pub async fn handle_filter_stream(
    request: GrpcBidiStreamRequest,
) -> Result<GrpcBidiStreamResponse, Status> {
    let messages = request.messages;
    let metadata = request.metadata;

    // Parse filter criteria from metadata
    let filter_type = metadata
        .get("x-filter-type")
        .and_then(|v| v.to_str().ok())
        .unwrap_or("all");

    let min_value = metadata
        .get("x-min-value")
        .and_then(|v| v.to_str().ok())
        .and_then(|s| s.parse::<i32>().ok())
        .unwrap_or(0);

    // Step 1: Deserialize and filter
    let mut filtered_items = Vec::new();

    for msg in messages.iter() {
        let item = recordservice::Record::decode(msg.clone())
            .map_err(|e| Status::invalid_argument(format!("Failed to decode: {}", e)))?;

        // Apply filter logic
        if filter_type == "all" || (filter_type == "high-value" && item.value >= min_value) {
            filtered_items.push(item);
        }
    }

    // Step 2: Transform filtered items
    let mut output_messages = Vec::with_capacity(filtered_items.len());

    for item in filtered_items {
        let response = recordservice::ProcessedRecord {
            id: item.id,
            original_value: item.value,
            processed_value: (item.value as f64 * 1.1) as i32,  // Apply multiplier
            filtered: false,
        };

        let mut buf = Vec::new();
        response.encode(&mut buf)
            .map_err(|e| Status::internal(format!("Encoding error: {}", e)))?;
        output_messages.push(Bytes::from(buf));
    }

    // Step 3: Return response with statistics
    let mut response_metadata = MetadataMap::new();
    response_metadata.insert(
        "x-input-count",
        messages.len().to_string().parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );
    response_metadata.insert(
        "x-output-count",
        output_messages.len().to_string().parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );
    response_metadata.insert(
        "x-filtered-count",
        (messages.len() - output_messages.len()).to_string().parse()
            .map_err(|e| Status::internal(format!("Invalid metadata value: {}", e)))?
    );

    Ok(GrpcBidiStreamResponse {
        messages: output_messages,
        metadata: response_metadata,
    })
}
```

## Key Patterns

### Message Collection
- All client messages are collected in a single `messages: Vec<Bytes>`
- Messages are provided as `Bytes` objects (protobuf serialized)
- No streaming iteration needed - full Vec is provided
- Order of messages is preserved

### Processing Strategy
1. **Collect**: All input messages received as Vec
2. **Validate**: Check all messages before processing (use `?` operator)
3. **Transform**: Process and generate output
4. **Serialize**: Encode response messages as Bytes
5. **Return**: Vec of response message Bytes wrapped in Result

### Error Handling
- Return `Result<T, tonic::Status>` for all handlers
- Use `?` operator for error propagation (NO `.unwrap()`)
- Map domain errors to appropriate Status codes:
  - `Status::invalid_argument()` for validation errors
  - `Status::unauthenticated()` for auth failures
  - `Status::not_found()` for missing resources
  - `Status::internal()` for processing errors
- Use `.map_err()` to convert errors to Status
- Per-message errors can be included in response messages (with ERROR status)

### Metadata
- Client streaming: Metadata passed in request, can be included in response
- Bidirectional streaming: Metadata passed in request, can be included in response
- Use metadata for non-payload information (timestamps, counts, filters)
- Access with `metadata.get(key).and_then(|v| v.to_str().ok())`
- Provide defaults with `.unwrap_or()` or `.unwrap_or_default()`

## Limits and Constraints

- **MAX_STREAM_MESSAGES**: 10,000 messages per stream
- **Resource Exhaustion**: Streams exceeding limit return `RESOURCE_EXHAUSTED` status
- **Memory**: All messages collected in memory - appropriate for moderate message counts
- **Atomicity**: All messages processed together (transaction-like semantics)

## Testing Client Streaming

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use prost::Message;
    use bytes::Bytes;
    use tonic::metadata::MetadataMap;

    mod messageservice {
        include!("messageservice.rs");
    }

    #[tokio::test]
    async fn test_batch_create_success() {
        // Create multiple input messages
        let items = vec![
            messageservice::Item {
                name: "Item 1".to_string(),
                value: 100,
            },
            messageservice::Item {
                name: "Item 2".to_string(),
                value: 200,
            },
            messageservice::Item {
                name: "Item 3".to_string(),
                value: 300,
            },
        ];

        let messages: Vec<Bytes> = items
            .iter()
            .map(|item| {
                let mut buf = Vec::new();
                item.encode(&mut buf).expect("Failed to encode Item protobuf");
                Bytes::from(buf)
            })
            .collect();

        // Create request
        let mut metadata = MetadataMap::new();
        metadata.insert("authorization", "Bearer token".parse().expect("Failed to parse authorization header"));

        let request = GrpcClientStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "BatchCreate".to_string(),
            metadata,
            messages,
        };

        // Mock repository
        let repository = Arc::new(MockItemRepository::new());

        // Call handler
        let response = handle_batch_create(request, repository).await.expect("Handler call failed");

        // Verify response
        let result = messageservice::BatchCreateResponse::decode(response.payload)
            .expect("Failed to decode BatchCreateResponse");

        assert_eq!(result.success_count, 3);
        assert_eq!(result.total_value, 600);
        assert!(response.metadata.get("x-batch-id").is_some());
        assert_eq!(
            response.metadata.get("x-count").expect("Missing x-count header").to_str().expect("Invalid x-count header"),
            "3"
        );
    }

    #[tokio::test]
    async fn test_batch_create_missing_authorization() {
        // Create request without authorization
        let items = vec![messageservice::Item {
            name: "Item 1".to_string(),
            value: 100,
        }];

        let messages: Vec<Bytes> = items
            .iter()
            .map(|item| {
                let mut buf = Vec::new();
                item.encode(&mut buf).expect("Failed to encode Item protobuf");
                Bytes::from(buf)
            })
            .collect();

        let request = GrpcClientStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "BatchCreate".to_string(),
            metadata: MetadataMap::new(),  // No authorization
            messages,
        };

        let repository = Arc::new(MockItemRepository::new());

        // Should return Unauthenticated error
        let result = handle_batch_create(request, repository).await;
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert_eq!(err.code(), tonic::Code::Unauthenticated);
        assert!(err.message().contains("Authentication required"));
    }

    #[tokio::test]
    async fn test_batch_create_invalid_item() {
        // Create request with invalid item (missing value)
        let items = vec![messageservice::Item {
            name: "Item 1".to_string(),
            value: 0,  // Invalid: value is 0
        }];

        let messages: Vec<Bytes> = items
            .iter()
            .map(|item| {
                let mut buf = Vec::new();
                item.encode(&mut buf).expect("Failed to encode Item protobuf");
                Bytes::from(buf)
            })
            .collect();

        let mut metadata = MetadataMap::new();
        metadata.insert("authorization", "Bearer token".parse().expect("Failed to parse authorization header"));

        let request = GrpcClientStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "BatchCreate".to_string(),
            metadata,
            messages,
        };

        let repository = Arc::new(MockItemRepository::new());

        // Should return InvalidArgument error
        let result = handle_batch_create(request, repository).await;
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert_eq!(err.code(), tonic::Code::InvalidArgument);
        assert!(err.message().contains("must have name and value"));
    }

    #[tokio::test]
    async fn test_batch_create_malformed_message() {
        // Create request with malformed protobuf
        let messages = vec![Bytes::from("invalid protobuf data")];

        let mut metadata = MetadataMap::new();
        metadata.insert("authorization", "Bearer token".parse().expect("Failed to parse authorization header"));

        let request = GrpcClientStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "BatchCreate".to_string(),
            metadata,
            messages,
        };

        let repository = Arc::new(MockItemRepository::new());

        // Should return InvalidArgument error for decode error
        let result = handle_batch_create(request, repository).await;
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert_eq!(err.code(), tonic::Code::InvalidArgument);
        assert!(err.message().contains("Failed to decode message"));
    }

    // Mock implementation for testing
    struct MockItemRepository;

    impl MockItemRepository {
        fn new() -> Self {
            Self
        }
    }

    #[async_trait::async_trait]
    impl ItemRepository for MockItemRepository {
        async fn with_transaction<F, Fut, T>(&self, f: F) -> Result<T, Box<dyn std::error::Error>>
        where
            F: FnOnce(&dyn Transaction) -> Fut + Send,
            Fut: std::future::Future<Output = Result<T, Status>> + Send,
        {
            let tx = MockTransaction;
            f(&tx).await.map_err(|e| e.to_string().into())
        }
    }

    struct MockTransaction;

    impl Transaction for MockTransaction {
        fn items(&self) -> &dyn ItemStore {
            &MockItemStore
        }
    }

    struct MockItemStore;

    #[async_trait::async_trait]
    impl ItemStore for MockItemStore {
        async fn create(&self, _name: &str, _value: i32) -> Result<(), Box<dyn std::error::Error>> {
            Ok(())
        }
    }
}
```

## Testing Bidirectional Streaming

```rust
#[cfg(test)]
mod bidi_tests {
    use super::*;
    use prost::Message;
    use bytes::Bytes;
    use tonic::metadata::MetadataMap;

    mod transformservice {
        include!("transformservice.rs");
    }

    #[tokio::test]
    async fn test_transform_stream_success() {
        // Create input messages
        let documents = vec![
            transformservice::Document {
                id: 1,
                content: "hello world".to_string(),
            },
            transformservice::Document {
                id: 2,
                content: "goodbye world".to_string(),
            },
        ];

        let messages: Vec<Bytes> = documents
            .iter()
            .map(|doc| {
                let mut buf = Vec::new();
                doc.encode(&mut buf).expect("Failed to encode Document protobuf");
                Bytes::from(buf)
            })
            .collect();

        // Create request
        let request = GrpcBidiStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "TransformStream".to_string(),
            metadata: MetadataMap::new(),
            messages,
        };

        // Call handler
        let response = handle_transform_stream(request).await.expect("Handler call failed");

        // Verify multiple response messages
        assert_eq!(response.messages.len(), 2);
        assert!(response.metadata.get("x-processed-count").is_some());
        assert_eq!(
            response.metadata.get("x-processed-count").expect("Missing x-processed-count header").to_str().expect("Invalid x-processed-count header"),
            "2"
        );

        // Verify each response
        for msg in response.messages {
            let result = transformservice::TransformResult::decode(msg).expect("Failed to decode TransformResult");
            assert_eq!(result.status, "SUCCESS");
            assert!(!result.transformed_content.is_empty());
            assert!(
                result.transformed_content.contains("HELLO") ||
                result.transformed_content.contains("GOODBYE")
            );
        }
    }

    #[tokio::test]
    async fn test_filter_stream_high_value() {
        mod recordservice {
            include!("recordservice.rs");
        }

        let records = vec![
            recordservice::Record { id: 1, value: 50 },
            recordservice::Record { id: 2, value: 150 },
            recordservice::Record { id: 3, value: 250 },
        ];

        let messages: Vec<Bytes> = records
            .iter()
            .map(|rec| {
                let mut buf = Vec::new();
                rec.encode(&mut buf).expect("Failed to encode Record protobuf");
                Bytes::from(buf)
            })
            .collect();

        let mut metadata = MetadataMap::new();
        metadata.insert("x-filter-type", "high-value".parse().expect("Failed to parse filter-type header"));
        metadata.insert("x-min-value", "100".parse().expect("Failed to parse min-value header"));

        let request = GrpcBidiStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "FilterStream".to_string(),
            metadata,
            messages,
        };

        let response = handle_filter_stream(request).await.expect("Handler call failed");

        // Only records with value >= 100 should be returned
        assert_eq!(response.messages.len(), 2);
        assert_eq!(
            response.metadata.get("x-output-count").expect("Missing x-output-count header").to_str().expect("Invalid x-output-count header"),
            "2"
        );
        assert_eq!(
            response.metadata.get("x-filtered-count").expect("Missing x-filtered-count header").to_str().expect("Invalid x-filtered-count header"),
            "1"
        );

        // Verify output values
        for msg in response.messages {
            let result = recordservice::ProcessedRecord::decode(msg).expect("Failed to decode ProcessedRecord");
            assert!(result.original_value >= 100);
        }
    }

    #[tokio::test]
    async fn test_filter_stream_malformed_input() {
        let messages = vec![Bytes::from("invalid protobuf")];

        let mut metadata = MetadataMap::new();
        metadata.insert("x-filter-type", "all".parse().expect("Failed to parse filter-type header"));

        let request = GrpcBidiStreamRequest {
            service_name: "myservice.MyService".to_string(),
            method_name: "FilterStream".to_string(),
            metadata,
            messages,
        };

        // Should return InvalidArgument error
        let result = handle_filter_stream(request).await;
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert_eq!(err.code(), tonic::Code::InvalidArgument);
        assert!(err.message().contains("Failed to decode"));
    }
}
```

## Running Tests

```bash
# Run all streaming tests
cargo test --package myservice

# Run specific test
cargo test test_batch_create_success

# Run with output
cargo test -- --nocapture

# Run async tests only
cargo test --features tokio-test
```

## Comparison with Other Patterns

| Aspect | Client Streaming | Bidirectional | Unary |
|--------|------------------|---------------|-------|
| Input | Multiple messages | Multiple messages | Single message |
| Output | Single response | Multiple messages | Single response |
| Use case | Batch operations | Stream processing | Simple requests |
| Message order | Important | Important | N/A |
| Atomicity | Full batch atomic | Per-message or batch | Single atomic |

## Common Pitfalls

### 1. Using .unwrap() Instead of ? Operator
```rust
// WRONG: Using .unwrap() causes panics
let item = messageservice::Item::decode(msg).unwrap();

// CORRECT: Use ? operator with map_err
let item = messageservice::Item::decode(msg)
    .map_err(|e| Status::invalid_argument(format!("Decode failed: {}", e)))?;
```

### 2. Not Handling All Message Errors
```rust
// WRONG: Failing entire stream on first error
for msg in messages {
    let item = messageservice::Item::decode(msg)?;  // Stops on first error
}

// CORRECT: Handle per-message errors
for msg in messages {
    match messageservice::Item::decode(msg) {
        Ok(item) => { /* process */ },
        Err(e) => {
            // Generate error response for this message
            let error_result = messageservice::ItemResult {
                status: "ERROR".to_string(),
                error_message: e.to_string(),
                ..Default::default()
            };
            let mut buf = Vec::new();
            error_result.encode(&mut buf)?;
            output_messages.push(Bytes::from(buf));
        }
    }
}
```

### 3. Forgetting to Serialize Response Messages
```rust
// WRONG: Returning protobuf objects instead of Bytes
let response = messageservice::Item { name: "test".to_string(), value: 1 };
output_messages.push(response);  // Type error!

// CORRECT: Serialize to Bytes
let response = messageservice::Item { name: "test".to_string(), value: 1 };
let mut buf = Vec::new();
response.encode(&mut buf)?;
output_messages.push(Bytes::from(buf));
```

### 4. Blocking Operations in Async Context
```rust
// WRONG: Blocking operation in async handler
async fn handle_batch_create(request: GrpcClientStreamRequest) -> Result<GrpcResponse, Status> {
    std::thread::sleep(std::time::Duration::from_secs(1));  // Blocks entire executor!
    Ok(response)
}

// CORRECT: Use async/await
async fn handle_batch_create(request: GrpcClientStreamRequest) -> Result<GrpcResponse, Status> {
    tokio::time::sleep(std::time::Duration::from_secs(1)).await;  // Non-blocking
    Ok(response)
}
```

See the gRPC documentation for more examples.
